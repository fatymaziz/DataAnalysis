{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d90fda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import opendatasets as od"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76bfa0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete this cell after the experiment--------------------------------****--------------------\n",
    "bugs_df= pd.read_csv(\"bugs_firefox.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20c4f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bugs_eclipse = pd.read_csv(\"bugs_eclipse.csv\")\n",
    "# bugs_firefox= pd.read_csv(\"bugs_firefox.csv\")\n",
    "# bugs_calendar= pd.read_csv(\"bugs_calendar.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaf7530",
   "metadata": {},
   "outputs": [],
   "source": [
    "bugs_eclipse['Type'] = np.where(bugs_eclipse['Severity'] == 'enhancement', \"enhancement\", \"defect\")\n",
    "bugs_eclipse.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c65b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bugs_firefox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b75c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bugs_calendar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6e0afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bugs_eclipse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa4c4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bugs_df = pd.concat([bugs_firefox,bugs_calendar,bugs_eclipse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da682a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bug ID</th>\n",
       "      <th>Product</th>\n",
       "      <th>Component</th>\n",
       "      <th>Assignee</th>\n",
       "      <th>Status</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Change Request</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1653320</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>Site Permissions</td>\n",
       "      <td>mconley@mozilla.com</td>\n",
       "      <td>UNCONFIRMED</td>\n",
       "      <td>---</td>\n",
       "      <td>Global sharing indicator blocks access to menu...</td>\n",
       "      <td>---</td>\n",
       "      <td>P2</td>\n",
       "      <td>S3</td>\n",
       "      <td>defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1355978</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>Tabbed Browser</td>\n",
       "      <td>nobody@mozilla.org</td>\n",
       "      <td>UNCONFIRMED</td>\n",
       "      <td>---</td>\n",
       "      <td>show tab favicons immediately</td>\n",
       "      <td>---</td>\n",
       "      <td>P2</td>\n",
       "      <td>S3</td>\n",
       "      <td>defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1404034</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>Theme</td>\n",
       "      <td>nobody@mozilla.org</td>\n",
       "      <td>UNCONFIRMED</td>\n",
       "      <td>---</td>\n",
       "      <td>Icon looks pixelated on gnome3</td>\n",
       "      <td>---</td>\n",
       "      <td>P2</td>\n",
       "      <td>S3</td>\n",
       "      <td>defect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Bug ID  Product         Component             Assignee       Status  \\\n",
       "0  1653320  Firefox  Site Permissions  mconley@mozilla.com  UNCONFIRMED   \n",
       "1  1355978  Firefox    Tabbed Browser   nobody@mozilla.org  UNCONFIRMED   \n",
       "2  1404034  Firefox             Theme   nobody@mozilla.org  UNCONFIRMED   \n",
       "\n",
       "  Resolution                                            Summary  \\\n",
       "0        ---  Global sharing indicator blocks access to menu...   \n",
       "1        ---                      show tab favicons immediately   \n",
       "2        ---                     Icon looks pixelated on gnome3   \n",
       "\n",
       "  Change Request Priority Severity    Type  \n",
       "0            ---       P2       S3  defect  \n",
       "1            ---       P2       S3  defect  \n",
       "2            ---       P2       S3  defect  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bugs_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a41fde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bug ID</th>\n",
       "      <th>Product</th>\n",
       "      <th>Component</th>\n",
       "      <th>Assignee</th>\n",
       "      <th>Status</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Change Request</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1847</th>\n",
       "      <td>651446</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>General</td>\n",
       "      <td>nobody@mozilla.org</td>\n",
       "      <td>UNCONFIRMED</td>\n",
       "      <td>---</td>\n",
       "      <td>Firefox does not close properly</td>\n",
       "      <td>---</td>\n",
       "      <td>--</td>\n",
       "      <td>S3</td>\n",
       "      <td>defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8912</th>\n",
       "      <td>1781895</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>General</td>\n",
       "      <td>nobody@mozilla.org</td>\n",
       "      <td>NEW</td>\n",
       "      <td>---</td>\n",
       "      <td>Intermittent browser/base/content/test/metaTag...</td>\n",
       "      <td>---</td>\n",
       "      <td>P3</td>\n",
       "      <td>S4</td>\n",
       "      <td>defect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Bug ID  Product Component            Assignee       Status Resolution  \\\n",
       "1847   651446  Firefox   General  nobody@mozilla.org  UNCONFIRMED        ---   \n",
       "8912  1781895  Firefox   General  nobody@mozilla.org          NEW        ---   \n",
       "\n",
       "                                                Summary Change Request  \\\n",
       "1847                    Firefox does not close properly            ---   \n",
       "8912  Intermittent browser/base/content/test/metaTag...            ---   \n",
       "\n",
       "     Priority Severity    Type  \n",
       "1847       --       S3  defect  \n",
       "8912       P3       S4  defect  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find duplicates in both bug list \n",
    "duplicate = bugs_df[bugs_df.duplicated('Summary')]\n",
    "duplicate.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01010b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bug ID</th>\n",
       "      <th>Product</th>\n",
       "      <th>Component</th>\n",
       "      <th>Assignee</th>\n",
       "      <th>Status</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Change Request</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4734</th>\n",
       "      <td>21482</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>File Handling</td>\n",
       "      <td>nobody@mozilla.org</td>\n",
       "      <td>NEW</td>\n",
       "      <td>---</td>\n",
       "      <td>Improvement to Save File dialog: folder based ...</td>\n",
       "      <td>---</td>\n",
       "      <td>P3</td>\n",
       "      <td>S3</td>\n",
       "      <td>enhancement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9367</th>\n",
       "      <td>23207</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>File Handling</td>\n",
       "      <td>nobody@mozilla.org</td>\n",
       "      <td>NEW</td>\n",
       "      <td>---</td>\n",
       "      <td>Options in Save As (location of saved images, ...</td>\n",
       "      <td>---</td>\n",
       "      <td>P5</td>\n",
       "      <td>S3</td>\n",
       "      <td>enhancement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4735</th>\n",
       "      <td>27493</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>File Handling</td>\n",
       "      <td>nobody@mozilla.org</td>\n",
       "      <td>NEW</td>\n",
       "      <td>---</td>\n",
       "      <td>Default open/save directory isn't smart</td>\n",
       "      <td>---</td>\n",
       "      <td>P3</td>\n",
       "      <td>S3</td>\n",
       "      <td>defect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Bug ID  Product      Component            Assignee Status Resolution  \\\n",
       "4734   21482  Firefox  File Handling  nobody@mozilla.org    NEW        ---   \n",
       "9367   23207  Firefox  File Handling  nobody@mozilla.org    NEW        ---   \n",
       "4735   27493  Firefox  File Handling  nobody@mozilla.org    NEW        ---   \n",
       "\n",
       "                                                Summary Change Request  \\\n",
       "4734  Improvement to Save File dialog: folder based ...            ---   \n",
       "9367  Options in Save As (location of saved images, ...            ---   \n",
       "4735            Default open/save directory isn't smart            ---   \n",
       "\n",
       "     Priority Severity         Type  \n",
       "4734       P3       S3  enhancement  \n",
       "9367       P5       S3  enhancement  \n",
       "4735       P3       S3       defect  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find duplicates in both bug list \n",
    "rslt_df = bugs_df.sort_values(by = ['Bug ID', 'Summary'])\n",
    "rslt_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "209e88f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bugs_df= bugs_df.drop_duplicates(subset=['Bug ID', 'Summary'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88b07d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(len(firefoxbugs), len(eclispsebugs), len(calendarbugs))\n",
    "\n",
    "len(bugs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8064f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame is written to Excel File successfully.\n"
     ]
    }
   ],
   "source": [
    "file_name = 'BugCombinedData.xlsx'\n",
    "  \n",
    "# saving the excel\n",
    "#bugs_df.to_excel(file_name)\n",
    "print('DataFrame is written to Excel File successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a31a1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bug ID</th>\n",
       "      <th>Product</th>\n",
       "      <th>Component</th>\n",
       "      <th>Assignee</th>\n",
       "      <th>Status</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Change Request</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1653320</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>Site Permissions</td>\n",
       "      <td>mconley@mozilla.com</td>\n",
       "      <td>UNCONFIRMED</td>\n",
       "      <td>---</td>\n",
       "      <td>Global sharing indicator blocks access to menu...</td>\n",
       "      <td>---</td>\n",
       "      <td>P2</td>\n",
       "      <td>S3</td>\n",
       "      <td>defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1355978</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>Tabbed Browser</td>\n",
       "      <td>nobody@mozilla.org</td>\n",
       "      <td>UNCONFIRMED</td>\n",
       "      <td>---</td>\n",
       "      <td>show tab favicons immediately</td>\n",
       "      <td>---</td>\n",
       "      <td>P2</td>\n",
       "      <td>S3</td>\n",
       "      <td>defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1404034</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>Theme</td>\n",
       "      <td>nobody@mozilla.org</td>\n",
       "      <td>UNCONFIRMED</td>\n",
       "      <td>---</td>\n",
       "      <td>Icon looks pixelated on gnome3</td>\n",
       "      <td>---</td>\n",
       "      <td>P2</td>\n",
       "      <td>S3</td>\n",
       "      <td>defect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Bug ID  Product         Component             Assignee       Status  \\\n",
       "0  1653320  Firefox  Site Permissions  mconley@mozilla.com  UNCONFIRMED   \n",
       "1  1355978  Firefox    Tabbed Browser   nobody@mozilla.org  UNCONFIRMED   \n",
       "2  1404034  Firefox             Theme   nobody@mozilla.org  UNCONFIRMED   \n",
       "\n",
       "  Resolution                                            Summary  \\\n",
       "0        ---  Global sharing indicator blocks access to menu...   \n",
       "1        ---                      show tab favicons immediately   \n",
       "2        ---                     Icon looks pixelated on gnome3   \n",
       "\n",
       "  Change Request Priority Severity    Type  \n",
       "0            ---       P2       S3  defect  \n",
       "1            ---       P2       S3  defect  \n",
       "2            ---       P2       S3  defect  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bugs_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcd39251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bug ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.273354e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.428482e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.148200e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.483578e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.412481e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.646532e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.802269e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Bug ID\n",
       "count  1.000000e+04\n",
       "mean   1.273354e+06\n",
       "std    4.428482e+05\n",
       "min    2.148200e+04\n",
       "25%    8.483578e+05\n",
       "50%    1.412481e+06\n",
       "75%    1.646532e+06\n",
       "max    1.802269e+06"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bugs_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee0a9f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Component</th>\n",
       "      <th>Assignee</th>\n",
       "      <th>Status</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Change Request</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>9570</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9998</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Firefox</td>\n",
       "      <td>General</td>\n",
       "      <td>nobody@mozilla.org</td>\n",
       "      <td>NEW</td>\n",
       "      <td>---</td>\n",
       "      <td>Intermittent browser/base/content/test/metaTag...</td>\n",
       "      <td>---</td>\n",
       "      <td>P3</td>\n",
       "      <td>S3</td>\n",
       "      <td>defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>10000</td>\n",
       "      <td>1653</td>\n",
       "      <td>9759</td>\n",
       "      <td>6147</td>\n",
       "      <td>10000</td>\n",
       "      <td>2</td>\n",
       "      <td>10000</td>\n",
       "      <td>4743</td>\n",
       "      <td>7521</td>\n",
       "      <td>6794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Product Component            Assignee Status Resolution  \\\n",
       "count     10000     10000               10000  10000      10000   \n",
       "unique        1        47                  74      2          1   \n",
       "top     Firefox   General  nobody@mozilla.org    NEW        ---   \n",
       "freq      10000      1653                9759   6147      10000   \n",
       "\n",
       "                                                  Summary Change Request  \\\n",
       "count                                               10000          10000   \n",
       "unique                                               9998              1   \n",
       "top     Intermittent browser/base/content/test/metaTag...            ---   \n",
       "freq                                                    2          10000   \n",
       "\n",
       "       Priority Severity    Type  \n",
       "count     10000     9570   10000  \n",
       "unique        6        6       3  \n",
       "top          P3       S3  defect  \n",
       "freq       4743     7521    6794  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bugs_df.describe(include='O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ba54211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Bug ID          10000 non-null  int64 \n",
      " 1   Product         10000 non-null  object\n",
      " 2   Component       10000 non-null  object\n",
      " 3   Assignee        10000 non-null  object\n",
      " 4   Status          10000 non-null  object\n",
      " 5   Resolution      10000 non-null  object\n",
      " 6   Summary         10000 non-null  object\n",
      " 7   Change Request  10000 non-null  object\n",
      " 8   Priority        10000 non-null  object\n",
      " 9   Severity        9570 non-null   object\n",
      " 10  Type            10000 non-null  object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "bugs_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb6817f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bugs_df=bugs_df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cbfa108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bugs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db0e1dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bugs_df = bugs_df[bugs_df[\"Severity\"].str.contains(\"--\")==False].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a226dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8640"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bugs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d4b576d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Bug ID</th>\n",
       "      <th>Product</th>\n",
       "      <th>Component</th>\n",
       "      <th>Assignee</th>\n",
       "      <th>Status</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Change Request</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1653320</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>Site Permissions</td>\n",
       "      <td>mconley@mozilla.com</td>\n",
       "      <td>UNCONFIRMED</td>\n",
       "      <td>---</td>\n",
       "      <td>Global sharing indicator blocks access to menu...</td>\n",
       "      <td>---</td>\n",
       "      <td>P2</td>\n",
       "      <td>S3</td>\n",
       "      <td>defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1355978</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>Tabbed Browser</td>\n",
       "      <td>nobody@mozilla.org</td>\n",
       "      <td>UNCONFIRMED</td>\n",
       "      <td>---</td>\n",
       "      <td>show tab favicons immediately</td>\n",
       "      <td>---</td>\n",
       "      <td>P2</td>\n",
       "      <td>S3</td>\n",
       "      <td>defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1404034</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>Theme</td>\n",
       "      <td>nobody@mozilla.org</td>\n",
       "      <td>UNCONFIRMED</td>\n",
       "      <td>---</td>\n",
       "      <td>Icon looks pixelated on gnome3</td>\n",
       "      <td>---</td>\n",
       "      <td>P2</td>\n",
       "      <td>S3</td>\n",
       "      <td>defect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   Bug ID  Product         Component             Assignee  \\\n",
       "0      0  1653320  Firefox  Site Permissions  mconley@mozilla.com   \n",
       "1      1  1355978  Firefox    Tabbed Browser   nobody@mozilla.org   \n",
       "2      2  1404034  Firefox             Theme   nobody@mozilla.org   \n",
       "\n",
       "        Status Resolution                                            Summary  \\\n",
       "0  UNCONFIRMED        ---  Global sharing indicator blocks access to menu...   \n",
       "1  UNCONFIRMED        ---                      show tab favicons immediately   \n",
       "2  UNCONFIRMED        ---                     Icon looks pixelated on gnome3   \n",
       "\n",
       "  Change Request Priority Severity    Type  \n",
       "0            ---       P2       S3  defect  \n",
       "1            ---       P2       S3  defect  \n",
       "2            ---       P2       S3  defect  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bugs_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b8020e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index             0\n",
       "Bug ID            0\n",
       "Product           0\n",
       "Component         0\n",
       "Assignee          0\n",
       "Status            0\n",
       "Resolution        0\n",
       "Summary           0\n",
       "Change Request    0\n",
       "Priority          0\n",
       "Severity          0\n",
       "Type              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "bugs_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ff35dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S3          7521\n",
       "S4          1083\n",
       "S2            27\n",
       "major          8\n",
       "critical       1\n",
       "Name: Severity, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bugs_df['Severity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d857544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2052"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropped rows with Type \"Enhancement\" because they are not a bug but a new feature\n",
    "indexSevere = bugs_df[ (bugs_df['Type'] == 'enhancement') & (bugs_df['Type'] == 'enhancement') ].index\n",
    "bugs_df.drop(indexSevere , inplace=True)\n",
    "bugs_df.head(15)\n",
    "len(indexSevere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c06c5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropped rows with Type \"Enhancement\" because they are not a bug but a new feature\n",
    "indexSevere = bugs_df[ (bugs_df['Type'] == 'task') & (bugs_df['Type'] == 'task') ].index\n",
    "bugs_df.drop(indexSevere , inplace=True)\n",
    "bugs_df.head(15)\n",
    "len(indexSevere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a648c560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_df= bugs_df[ (bugs_df['Severity'] == 'normal')]\n",
    "len(normal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1dc68dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5289"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S3_df= bugs_df[ (bugs_df['Severity'] == 'S3')]\n",
    "len(S3_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8378d600",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Catagorise the severity level into a Severe and Non Severe to make it a binary problem\n",
    "bugs_df.loc[bugs_df[\"Severity\"] == \"blocker\", \"Severity\"] = 'Severe'\n",
    "bugs_df.loc[bugs_df[\"Severity\"] == \"critical\", \"Severity\"] = 'Severe'\n",
    "bugs_df.loc[bugs_df[\"Severity\"] == \"major\", \"Severity\"] = 'Severe'\n",
    "bugs_df.loc[bugs_df[\"Severity\"] == \"S1\", \"Severity\"] = 'Severe'\n",
    "bugs_df.loc[bugs_df[\"Severity\"] == \"S2\", \"Severity\"] = 'Severe'\n",
    "bugs_df.loc[bugs_df[\"Severity\"] == \"S3\", \"Severity\"] = 'NonSevere'\n",
    "bugs_df.loc[bugs_df[\"Severity\"] == \"normal\", \"Severity\"] = 'NonSevere'\n",
    "bugs_df.loc[bugs_df[\"Severity\"] == \"minor\", \"Severity\"] = 'NonSevere'\n",
    "bugs_df.loc[bugs_df[\"Severity\"] == \"trivial\", \"Severity\"] = 'NonSevere'\n",
    "bugs_df.loc[bugs_df[\"Severity\"] == \"S4\", \"Severity\"] = 'NonSevere'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d00af999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NonSevere', 'Severe'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bugs_df.Severity.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b111fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6298"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bugs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "482f096c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bugs_df.Summary.str.contains(\"Browser\").sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "32c78f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Bug ID</th>\n",
       "      <th>Product</th>\n",
       "      <th>Component</th>\n",
       "      <th>Assignee</th>\n",
       "      <th>Status</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Change Request</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1653320</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>Site Permissions</td>\n",
       "      <td>mconley@mozilla.com</td>\n",
       "      <td>UNCONFIRMED</td>\n",
       "      <td>---</td>\n",
       "      <td>Global sharing indicator blocks access to menu...</td>\n",
       "      <td>---</td>\n",
       "      <td>P2</td>\n",
       "      <td>NonSevere</td>\n",
       "      <td>defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1355978</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>Tabbed Browser</td>\n",
       "      <td>nobody@mozilla.org</td>\n",
       "      <td>UNCONFIRMED</td>\n",
       "      <td>---</td>\n",
       "      <td>show tab favicons immediately</td>\n",
       "      <td>---</td>\n",
       "      <td>P2</td>\n",
       "      <td>NonSevere</td>\n",
       "      <td>defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1404034</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>Theme</td>\n",
       "      <td>nobody@mozilla.org</td>\n",
       "      <td>UNCONFIRMED</td>\n",
       "      <td>---</td>\n",
       "      <td>Icon looks pixelated on gnome3</td>\n",
       "      <td>---</td>\n",
       "      <td>P2</td>\n",
       "      <td>NonSevere</td>\n",
       "      <td>defect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   Bug ID  Product         Component             Assignee  \\\n",
       "0      0  1653320  Firefox  Site Permissions  mconley@mozilla.com   \n",
       "1      1  1355978  Firefox    Tabbed Browser   nobody@mozilla.org   \n",
       "2      2  1404034  Firefox             Theme   nobody@mozilla.org   \n",
       "\n",
       "        Status Resolution                                            Summary  \\\n",
       "0  UNCONFIRMED        ---  Global sharing indicator blocks access to menu...   \n",
       "1  UNCONFIRMED        ---                      show tab favicons immediately   \n",
       "2  UNCONFIRMED        ---                     Icon looks pixelated on gnome3   \n",
       "\n",
       "  Change Request Priority   Severity    Type  \n",
       "0            ---       P2  NonSevere  defect  \n",
       "1            ---       P2  NonSevere  defect  \n",
       "2            ---       P2  NonSevere  defect  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bugs_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "540bc282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NonSevere    6264\n",
       "Severe         34\n",
       "Name: Severity, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bugs_df['Severity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73f1d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6fbca2",
   "metadata": {},
   "source": [
    "# Split data into test and train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e197d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of training data: 4030\n",
      "No. of validation data: 1008\n",
      "No. of testing data: 1260\n"
     ]
    }
   ],
   "source": [
    "# for i in rang(1,3):\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_data, testing_data = train_test_split(bugs_df, test_size=0.2, random_state=25)\n",
    "training_data, validation_data = train_test_split(training_data, test_size=0.2, random_state=25)\n",
    "\n",
    "print(f\"No. of training data: {training_data.shape[0]}\")\n",
    "print(f\"No. of validation data: {validation_data.shape[0]}\")\n",
    "print(f\"No. of testing data: {testing_data.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0bd0ddb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4030"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingdataset = len(training_data)\n",
    "trainingdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77368897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1260"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testingdataset = len(testing_data)\n",
    "testingdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9be2019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_df=training_data.reset_index()\n",
    "validation_data_df=validation_data.reset_index()\n",
    "testing_data_df=testing_data.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed497faf",
   "metadata": {},
   "source": [
    "# Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad899db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/abyte/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f1c1494",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenise the Summary text\n",
    "def nlpsteps(x):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', str(x))\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    all_stopwords = stopwords.words('english')\n",
    "    all_stopwords.remove('not')\n",
    "    review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
    "    review = ' '.join(review)\n",
    "    return review\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "86bcc1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_trainingdata = []\n",
    "for i in range(0,trainingdataset):\n",
    "    review = nlpsteps(str(training_data_df['Summary'][i]))\n",
    "    corpus_trainingdata.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c21b1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corpus_trainingdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97c7137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Corpus data splitted into separate words\n",
    "def convert(corpus_trainingdata):\n",
    "    return ([i for item in corpus_trainingdata for i in item.split()])\n",
    "     \n",
    "print( convert(corpus_trainingdata))\n",
    "splittedWords = convert(corpus_trainingdata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7725ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts of each words in the corpus\n",
    "import collections\n",
    "def getwordcounts(splittedWords):\n",
    "    occurrences = collections.Counter(splittedWords)\n",
    "    print(occurrences)\n",
    "    return occurrences\n",
    "\n",
    "splitted_words=getwordcounts(splittedWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05848f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(splitted_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02006634",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_words.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d477ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converted collection.counter into dictionary\n",
    "splitted_words_dict = dict(splitted_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b7fc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = splitted_words_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c48323",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9d92be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that returns the counts for each words that falls in Severe or Non Severe category\n",
    "def get_distribution(val):\n",
    "    records = training_data_df[\n",
    "        training_data_df[\"Summary\"].str.contains(val)\n",
    "    ]\n",
    "    \n",
    "    if len(records) > 0:\n",
    "        res = training_data_df[\n",
    "            training_data_df[\"Summary\"].str.contains(val)\n",
    "        ][\"Severity\"].value_counts(dropna=False)\n",
    "        return dict(res)\n",
    "    return None\n",
    "    \n",
    "get_distribution(\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287bd89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(keys), len(list(set(keys)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47e159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {}\n",
    "for key in keys:\n",
    "    res = get_distribution(key)\n",
    "    if res:\n",
    "        all_data[key] = res\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8948a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4869aac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns Severe ratio\n",
    "def get_r1(ns,s):\n",
    "    return s/(s+ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0f6d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_r1(203, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aed7679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns NonSevere ratio\n",
    "def get_r2(ns,s):\n",
    "    return ns/(s+ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7c808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_r2(203,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8912a065",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload_train = {}\n",
    "for key, value in all_data.items():\n",
    "    ns = value.get('NonSevere', 0)\n",
    "    s = value.get('Severe',0)\n",
    "    \n",
    "    r1 = get_r1(ns, s)\n",
    "    r2 = get_r2(ns, s)\n",
    "    \n",
    "    payload_train[key]= {\n",
    "        'r1': r1,\n",
    "        'r2': r2\n",
    "    }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f48e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d564b57e",
   "metadata": {},
   "source": [
    "## Test dictionaries with validation dataset on different thresholds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15bf9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Incase of equal frequency the classifier will be Severe\n",
    "def classifier(Summary,severedictionary_list,nonseveredictionary_list):\n",
    "  \n",
    "    summaryList = Summary.split()\n",
    "    mytest_severe = len(set(severedictionary_list).intersection(summaryList))\n",
    "    mytest_nonsevere = len(set(nonseveredictionary_list).intersection(summaryList))\n",
    "    \n",
    "    if mytest_severe >= mytest_nonsevere:\n",
    "        tag = \"Severe\"\n",
    "    elif mytest_severe < mytest_nonsevere:\n",
    "        tag = \"NonSevere\"\n",
    "   \n",
    "    return tag\n",
    "   \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862e5d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#severe_threshold = [0.0, 0.1 ,0.2, 0.3 ,0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "# severe_threshold = [x * 0.01 for x in range(0, 100)] + [0.2, 0.5, 1.0]\n",
    "# severe_threshold=[x * 0.001 for x in range(0, 1000)] + [0.2, 0.5, 1.0]\n",
    "severe_threshold = [0.0, 0.1 ,0.2, 0.3 ,0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "nonsevere_threshold = [0.0, 0.1 ,0.2, 0.3 ,0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ad7e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def functionname(x, y):\n",
    "# \"\"\"x is actually....\n",
    "#     y is actuallly ....\"\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ac8fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that creates dictionary on different threholds and tests with validation data and returns the confusion matrix and accuracy scores of each dictionary\n",
    "def dictionary_onthresholds(severe_threshold, nonsevere_threshold, dataset):\n",
    "\n",
    "    severe_dictionary = {}\n",
    "    nonsevere_dictionary = {}\n",
    "    for keyy in payload_train:\n",
    "        if payload_train[keyy]['r1'] >= severe_threshold:\n",
    "            severe_dictionary[keyy] = payload_train[keyy]\n",
    "        \n",
    "        if payload_train[keyy]['r2'] >= nonsevere_threshold:\n",
    "            nonsevere_dictionary[keyy] = payload_train[keyy]\n",
    "            \n",
    "    severedictionary_list = list(severe_dictionary.keys())\n",
    "    print(severedictionary_list)\n",
    "    nonseveredictionary_list = list(nonsevere_dictionary.keys())\n",
    "    print(nonseveredictionary_list)\n",
    "    \n",
    "    dataset[\"Summary\"]  = dataset[\"Summary\"].apply(lambda x: nlpsteps(x))\n",
    "    \n",
    "    dataset[\"my_tag\"] = dataset[\"Summary\"].apply(lambda x: classifier(x,severedictionary_list,nonseveredictionary_list))\n",
    "    \n",
    "   \n",
    "    TP = 0 \n",
    "    for d in dataset.iterrows():\n",
    "        if ((d[1][\"my_tag\"]== \"Severe\") & (d[1][\"Severity\"]== \"Severe\")):\n",
    "            TP = TP+1\n",
    "    FP = 0 \n",
    "    for d in dataset.iterrows():\n",
    "        if (d[1][\"my_tag\"]== \"Severe\" )& (d[1][\"Severity\"]== \"NonSevere\"):\n",
    "            FP = FP+1\n",
    "    TN = 0 \n",
    "    for d in dataset.iterrows():\n",
    "        if (d[1][\"my_tag\"]== \"NonSevere\") & (d[1][\"Severity\"]== \"NonSevere\"):\n",
    "            TN = TN+1\n",
    "    FN = 0 \n",
    "    for d in dataset.iterrows():\n",
    "        if (d[1][\"my_tag\"]== \"NonSevere\") & (d[1][\"Severity\"]== \"Severe\"):\n",
    "            FN = FN+1\n",
    "\n",
    "    confusion_matrix = {\n",
    "        \"TP\": TP,\n",
    "        \"FP\": FP,\n",
    "        \"TN\": TN,\n",
    "        \"FN\": FN\n",
    "        \n",
    "    }\n",
    "    \n",
    "    confusion_matrix[\"Precision\"]= confusion_matrix[\"TP\"]/(confusion_matrix[\"TP\"]+confusion_matrix[\"FP\"]) if (confusion_matrix[\"TP\"]) !=0 else 0\n",
    "    confusion_matrix[\"Recall\"]= confusion_matrix[\"TP\"]/(confusion_matrix[\"TP\"]+confusion_matrix[\"FN\"]) if (confusion_matrix[\"TP\"]) !=0 else 0\n",
    "    confusion_matrix[\"F1Score\"] = 2*(confusion_matrix[\"Precision\"] * confusion_matrix[\"Recall\"])/(confusion_matrix[\"Precision\"] + confusion_matrix[\"Recall\"]) if (confusion_matrix[\"Precision\"] + confusion_matrix[\"Recall\"]) != 0 else 0\n",
    "                                                                                                   \n",
    "    \n",
    "    return confusion_matrix\n",
    "   \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55655f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary_onthresholds(0.3,1.0,validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed22a75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c3d78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "possibleThesholdCombination = list(itertools.product(severe_threshold, nonsevere_threshold))\n",
    "result_list=[]\n",
    "for i in possibleThesholdCombination:\n",
    "   \n",
    "    severe_randomthreshold = i[0]\n",
    "    nonsevere_randomthreshold = i[1]\n",
    "    \n",
    "    count = dictionary_onthresholds(severe_randomthreshold,nonsevere_randomthreshold,validation_data)\n",
    "    result_dictionary = {\n",
    "     \"severe_threshold\": severe_randomthreshold,\n",
    "     \"nonsevere_threshold\":nonsevere_randomthreshold,\n",
    "#       \"performance\": count\n",
    "    \n",
    "    \n",
    "    }\n",
    "    result_dictionary.update(count)\n",
    "    result_list.append(result_dictionary)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7d22ef",
   "metadata": {},
   "outputs": [],
   "source": [
    " result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1adac53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#F1score of the dictionaries that was tested with  validation data\n",
    "F1Score_df = pd.DataFrame(result_list)\n",
    "F1Score_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987fe025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max F1score that was tested with the validation data\n",
    "F1Score_df[F1Score_df['F1Score']==F1Score_df['F1Score'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930cada1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "F1Score_df.sort_values(by=['F1Score'], ascending=False).head(50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3776c0b",
   "metadata": {},
   "source": [
    "### Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f85b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#F1score of the dictionaries that was tested with  testing data\n",
    "count = dictionary_onthresholds(0.2,0.9,testing_data)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7ec093",
   "metadata": {},
   "source": [
    "# ML Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ab9efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------ML Experiment Starts---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d1f4a044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenised the training data again and stored into a different variable\n",
    "trainingdata_tokenised = []\n",
    "for i in range(0,trainingdataset):\n",
    "    review = nlpsteps(str(training_data_df['Summary'][i]))\n",
    "    trainingdata_tokenised.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5424d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenised the testing data\n",
    "testingdata_tokenised = []\n",
    "for i in range(0,testingdataset):\n",
    "    review = nlpsteps(str(testing_data_df['Summary'][i]))\n",
    "    testingdata_tokenised.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2c2e7de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Reports\n",
      "\n",
      "500\n",
      "MultinomialNB -------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   NonSevere       1.00      1.00      1.00      1254\n",
      "      Severe       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.99      1260\n",
      "   macro avg       0.50      0.50      0.50      1260\n",
      "weighted avg       0.99      0.99      0.99      1260\n",
      "\n",
      "\n",
      "Logistic Regression-------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   NonSevere       1.00      1.00      1.00      1254\n",
      "      Severe       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           1.00      1260\n",
      "   macro avg       0.50      0.50      0.50      1260\n",
      "weighted avg       0.99      1.00      0.99      1260\n",
      "\n",
      "\n",
      "SVM -------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   NonSevere       1.00      0.98      0.99      1254\n",
      "      Severe       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.98      1260\n",
      "   macro avg       0.50      0.49      0.49      1260\n",
      "weighted avg       0.99      0.98      0.98      1260\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Reports\n",
      "\n",
      "1000\n",
      "MultinomialNB -------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   NonSevere       1.00      1.00      1.00      1254\n",
      "      Severe       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.99      1260\n",
      "   macro avg       0.50      0.50      0.50      1260\n",
      "weighted avg       0.99      0.99      0.99      1260\n",
      "\n",
      "\n",
      "Logistic Regression-------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   NonSevere       1.00      1.00      1.00      1254\n",
      "      Severe       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           1.00      1260\n",
      "   macro avg       0.50      0.50      0.50      1260\n",
      "weighted avg       0.99      1.00      0.99      1260\n",
      "\n",
      "\n",
      "SVM -------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   NonSevere       1.00      0.99      0.99      1254\n",
      "      Severe       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.99      1260\n",
      "   macro avg       0.50      0.50      0.50      1260\n",
      "weighted avg       0.99      0.99      0.99      1260\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Reports\n",
      "\n",
      "3000\n",
      "MultinomialNB -------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   NonSevere       1.00      1.00      1.00      1254\n",
      "      Severe       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.99      1260\n",
      "   macro avg       0.50      0.50      0.50      1260\n",
      "weighted avg       0.99      0.99      0.99      1260\n",
      "\n",
      "\n",
      "Logistic Regression-------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   NonSevere       1.00      1.00      1.00      1254\n",
      "      Severe       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           1.00      1260\n",
      "   macro avg       0.50      0.50      0.50      1260\n",
      "weighted avg       0.99      1.00      0.99      1260\n",
      "\n",
      "\n",
      "SVM -------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   NonSevere       1.00      1.00      1.00      1254\n",
      "      Severe       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.99      1260\n",
      "   macro avg       0.50      0.50      0.50      1260\n",
      "weighted avg       0.99      0.99      0.99      1260\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Count Vectorised the Summary text in the training data and this for and transforms the \"tokenised Summary\" into an array\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "max_feature_list = []\n",
    "max_feature_accuracy = []\n",
    "SVM_list= []\n",
    "\n",
    "    \n",
    "features = [500,1000,3000]\n",
    "\n",
    "for i in features:\n",
    "\n",
    "    cv = CountVectorizer(max_features = i)\n",
    "    X_train = cv.fit_transform(trainingdata_tokenised).toarray()\n",
    "    Y_train = training_data.iloc[:, -2].values\n",
    "    testingdata_vector = cv.transform(testingdata_tokenised)\n",
    "    X_test = testingdata_vector.toarray()\n",
    "    y_test = testing_data_df.iloc[:, -2].values\n",
    "    \n",
    "#------------------------------------SVM------------------------------------------------------------------\n",
    "    C_hyperparameter = [0.1,0.5,1,5,10,20,50,100]\n",
    "   \n",
    "    SVM_accuracy_list = []\n",
    "    \n",
    "    for c in C_hyperparameter:\n",
    "        SVM_dict = {}\n",
    "    \n",
    "        svm_model = SVC(C = c, kernel='linear', gamma='auto')\n",
    "        svm_model.fit(X_train,Y_train)\n",
    "\n",
    "        svm_pred = svm_model.predict(X_test)\n",
    "        svm_model = confusion_matrix(y_test, svm_pred)\n",
    "\n",
    "        SVM_accuracy_list= accuracy_score(y_test, svm_pred)\n",
    "        SVM_dict = {\"features\":i,\"C\":c, \"confusionmatrix\":svm_model,\"Accuracy\": SVM_accuracy_list }\n",
    "        SVM_list.append(SVM_dict)\n",
    "        SVM_list\n",
    "    \n",
    "    \n",
    " #-------------------------------------Naive Bayes-------------------------------------------------------------\n",
    "    classifier = MultinomialNB()\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    \n",
    "    MultinomialNB_pred = classifier.predict(X_test)\n",
    "    \n",
    "    cm_MB = confusion_matrix(y_test, MultinomialNB_pred)\n",
    "    max_feature_accuracy = accuracy_score(y_test, MultinomialNB_pred)\n",
    "    \n",
    "    maxfeature_dict = {\"features\":i, \"confusionmatrix\": cm_MB ,\"Accuracy\": max_feature_accuracy }\n",
    "    max_feature_list.append(maxfeature_dict)\n",
    "    \n",
    "    #-------------------------------------Logistic Regression-------------------------------------------------------------\n",
    "    \n",
    "    lr_model = LogisticRegression()\n",
    "    lr_model.fit(X_train,Y_train)\n",
    "    \n",
    "    lr_pred = lr_model.predict(X_test)\n",
    "    \n",
    "  \n",
    "    cm_lr = confusion_matrix(y_test, lr_pred)\n",
    "    max_feature_accuracy =  accuracy_score(y_test, lr_pred)\n",
    "\n",
    "    maxfeature_dict = {\"features\":i, \"confusionmatrix\": cm_lr ,\"Accuracy\": max_feature_accuracy }\n",
    "    max_feature_list.append(maxfeature_dict)\n",
    "    \n",
    "    #------------------------------------Classification Report------------------------------------------------------------------\n",
    "    \n",
    "    print('Classification Reports\\n')\n",
    "    print(i)\n",
    "#     print(f'Dummy Classifer -------------------\\n{classification_report(y_test, dummy_pred)}\\n')\n",
    "    print(f'MultinomialNB -------------------\\n{classification_report(y_test, MultinomialNB_pred)}\\n')\n",
    "    print(f'Logistic Regression-------------------\\n{classification_report(y_test, lr_pred)}\\n')\n",
    "    print(f'SVM -------------------\\n{classification_report(y_test, svm_pred)}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5b128bd3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'features': 500,\n",
       "  'confusionmatrix': array([[1253,    1],\n",
       "         [   6,    0]]),\n",
       "  'Accuracy': 0.9944444444444445},\n",
       " {'features': 500,\n",
       "  'confusionmatrix': array([[1254,    0],\n",
       "         [   6,    0]]),\n",
       "  'Accuracy': 0.9952380952380953},\n",
       " {'features': 1000,\n",
       "  'confusionmatrix': array([[1252,    2],\n",
       "         [   6,    0]]),\n",
       "  'Accuracy': 0.9936507936507937},\n",
       " {'features': 1000,\n",
       "  'confusionmatrix': array([[1254,    0],\n",
       "         [   6,    0]]),\n",
       "  'Accuracy': 0.9952380952380953},\n",
       " {'features': 3000,\n",
       "  'confusionmatrix': array([[1253,    1],\n",
       "         [   6,    0]]),\n",
       "  'Accuracy': 0.9944444444444445},\n",
       " {'features': 3000,\n",
       "  'confusionmatrix': array([[1254,    0],\n",
       "         [   6,    0]]),\n",
       "  'Accuracy': 0.9952380952380953}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9186db1a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>confusionmatrix</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>[[1253, 1], [6, 0]]</td>\n",
       "      <td>0.994444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500</td>\n",
       "      <td>[[1254, 0], [6, 0]]</td>\n",
       "      <td>0.995238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>[[1252, 2], [6, 0]]</td>\n",
       "      <td>0.993651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>[[1254, 0], [6, 0]]</td>\n",
       "      <td>0.995238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000</td>\n",
       "      <td>[[1253, 1], [6, 0]]</td>\n",
       "      <td>0.994444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3000</td>\n",
       "      <td>[[1254, 0], [6, 0]]</td>\n",
       "      <td>0.995238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   features      confusionmatrix  Accuracy\n",
       "0       500  [[1253, 1], [6, 0]]  0.994444\n",
       "1       500  [[1254, 0], [6, 0]]  0.995238\n",
       "2      1000  [[1252, 2], [6, 0]]  0.993651\n",
       "3      1000  [[1254, 0], [6, 0]]  0.995238\n",
       "4      3000  [[1253, 1], [6, 0]]  0.994444\n",
       "5      3000  [[1254, 0], [6, 0]]  0.995238"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(max_feature_list)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5bcd2eb4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'features': 500,\n",
       "  'C': 0.1,\n",
       "  'confusionmatrix': array([[1254,    0],\n",
       "         [   6,    0]]),\n",
       "  'Accuracy': 0.9952380952380953},\n",
       " {'features': 500,\n",
       "  'C': 0.5,\n",
       "  'confusionmatrix': array([[1254,    0],\n",
       "         [   6,    0]]),\n",
       "  'Accuracy': 0.9952380952380953},\n",
       " {'features': 500,\n",
       "  'C': 1,\n",
       "  'confusionmatrix': array([[1252,    2],\n",
       "         [   6,    0]]),\n",
       "  'Accuracy': 0.9936507936507937},\n",
       " {'features': 500,\n",
       "  'C': 5,\n",
       "  'confusionmatrix': array([[1246,    8],\n",
       "         [   6,    0]]),\n",
       "  'Accuracy': 0.9888888888888889},\n",
       " {'features': 500,\n",
       "  'C': 10,\n",
       "  'confusionmatrix': array([[1239,   15],\n",
       "         [   6,    0]]),\n",
       "  'Accuracy': 0.9833333333333333},\n",
       " {'features': 500,\n",
       "  'C': 20,\n",
       "  'confusionmatrix': array([[1239,   15],\n",
       "         [   6,    0]]),\n",
       "  'Accuracy': 0.9833333333333333},\n",
       " {'features': 500,\n",
       "  'C': 50,\n",
       "  'confusionmatrix': array([[1236,   18],\n",
       "         [   6,    0]]),\n",
       "  'Accuracy': 0.9809523809523809},\n",
       " {'features': 500,\n",
       "  'C': 100,\n",
       "  'confusionmatrix': array([[1231,   23],\n",
       "         [   6,    0]]),\n",
       "  'Accuracy': 0.976984126984127},\n",
       " {'features': 1000,\n",
       "  'C': 0.1,\n",
       "  'confusionmatrix': array([[1254,    0],\n",
       "         [   6,    0]]),\n",
       "  'Accuracy': 0.9952380952380953},\n",
       " {'features': 1000,\n",
       "  'C': 0.5,\n",
       "  'confusionmatrix': array([[1253,    1],\n",
       "         [   6,    0]]),\n",
       "  'Accuracy': 0.9944444444444445},\n",
       " {'features': 1000,\n",
       "  'C': 1,\n",
       "  'confusionmatrix': array([[1252,    2],\n",
       "         [   6,    0]]),\n",
       "  'Accuracy': 0.9936507936507937},\n",
       " {'features': 1000,\n",
       "  'C': 5,\n",
       "  'confusionmatrix': array([[1245,    9],\n",
       "         [   6,    0]]),\n",
       "  'Accuracy': 0.9880952380952381},\n",
       " {'features': 1000,\n",
       "  'C': 10,\n",
       "  'confusionmatrix': array([[1243,   11],\n",
       "         [   6,    0]]),\n",
       "  'Accuracy': 0.9865079365079366},\n",
       " {'features': 1000,\n",
       "  'C': 20,\n",
       "  'confusionmatrix': array([[1243,   11],\n",
       "         [   6,    0]]),\n",
       "  'Accuracy': 0.9865079365079366},\n",
       " {'features': 1000,\n",
       "  'C': 50,\n",
       "  'confusionmatrix': array([[1243,   11],\n",
       "         [   6,    0]]),\n",
       "  'Accuracy': 0.9865079365079366},\n",
       " {'features': 1000,\n",
       "  'C': 100,\n",
       "  'confusionmatrix': array([[1243,   11],\n",
       "         [   6,    0]]),\n",
       "  'Accuracy': 0.9865079365079366},\n",
       " {'features': 3000,\n",
       "  'C': 0.1,\n",
       "  'confusionmatrix': array([[1254,    0],\n",
       "         [   6,    0]]),\n",
       "  'Accuracy': 0.9952380952380953},\n",
       " {'features': 3000,\n",
       "  'C': 0.5,\n",
       "  'confusionmatrix': array([[1253,    1],\n",
       "         [   6,    0]]),\n",
       "  'Accuracy': 0.9944444444444445},\n",
       " {'features': 3000,\n",
       "  'C': 1,\n",
       "  'confusionmatrix': array([[1253,    1],\n",
       "         [   6,    0]]),\n",
       "  'Accuracy': 0.9944444444444445},\n",
       " {'features': 3000,\n",
       "  'C': 5,\n",
       "  'confusionmatrix': array([[1248,    6],\n",
       "         [   6,    0]]),\n",
       "  'Accuracy': 0.9904761904761905},\n",
       " {'features': 3000,\n",
       "  'C': 10,\n",
       "  'confusionmatrix': array([[1248,    6],\n",
       "         [   6,    0]]),\n",
       "  'Accuracy': 0.9904761904761905},\n",
       " {'features': 3000,\n",
       "  'C': 20,\n",
       "  'confusionmatrix': array([[1248,    6],\n",
       "         [   6,    0]]),\n",
       "  'Accuracy': 0.9904761904761905},\n",
       " {'features': 3000,\n",
       "  'C': 50,\n",
       "  'confusionmatrix': array([[1248,    6],\n",
       "         [   6,    0]]),\n",
       "  'Accuracy': 0.9904761904761905},\n",
       " {'features': 3000,\n",
       "  'C': 100,\n",
       "  'confusionmatrix': array([[1248,    6],\n",
       "         [   6,    0]]),\n",
       "  'Accuracy': 0.9904761904761905}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "61cf3b31",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>C</th>\n",
       "      <th>confusionmatrix</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[[1254, 0], [6, 0]]</td>\n",
       "      <td>0.995238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[[1254, 0], [6, 0]]</td>\n",
       "      <td>0.995238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[1252, 2], [6, 0]]</td>\n",
       "      <td>0.993651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[[1246, 8], [6, 0]]</td>\n",
       "      <td>0.988889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[[1239, 15], [6, 0]]</td>\n",
       "      <td>0.983333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>500</td>\n",
       "      <td>20.0</td>\n",
       "      <td>[[1239, 15], [6, 0]]</td>\n",
       "      <td>0.983333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>500</td>\n",
       "      <td>50.0</td>\n",
       "      <td>[[1236, 18], [6, 0]]</td>\n",
       "      <td>0.980952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>500</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[1231, 23], [6, 0]]</td>\n",
       "      <td>0.976984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[[1254, 0], [6, 0]]</td>\n",
       "      <td>0.995238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[[1253, 1], [6, 0]]</td>\n",
       "      <td>0.994444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[1252, 2], [6, 0]]</td>\n",
       "      <td>0.993651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[[1245, 9], [6, 0]]</td>\n",
       "      <td>0.988095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[[1243, 11], [6, 0]]</td>\n",
       "      <td>0.986508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>[[1243, 11], [6, 0]]</td>\n",
       "      <td>0.986508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>[[1243, 11], [6, 0]]</td>\n",
       "      <td>0.986508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[1243, 11], [6, 0]]</td>\n",
       "      <td>0.986508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[[1254, 0], [6, 0]]</td>\n",
       "      <td>0.995238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[[1253, 1], [6, 0]]</td>\n",
       "      <td>0.994444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[1253, 1], [6, 0]]</td>\n",
       "      <td>0.994444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[[1248, 6], [6, 0]]</td>\n",
       "      <td>0.990476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[[1248, 6], [6, 0]]</td>\n",
       "      <td>0.990476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>[[1248, 6], [6, 0]]</td>\n",
       "      <td>0.990476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>[[1248, 6], [6, 0]]</td>\n",
       "      <td>0.990476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[1248, 6], [6, 0]]</td>\n",
       "      <td>0.990476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    features      C       confusionmatrix  Accuracy\n",
       "0        500    0.1   [[1254, 0], [6, 0]]  0.995238\n",
       "1        500    0.5   [[1254, 0], [6, 0]]  0.995238\n",
       "2        500    1.0   [[1252, 2], [6, 0]]  0.993651\n",
       "3        500    5.0   [[1246, 8], [6, 0]]  0.988889\n",
       "4        500   10.0  [[1239, 15], [6, 0]]  0.983333\n",
       "5        500   20.0  [[1239, 15], [6, 0]]  0.983333\n",
       "6        500   50.0  [[1236, 18], [6, 0]]  0.980952\n",
       "7        500  100.0  [[1231, 23], [6, 0]]  0.976984\n",
       "8       1000    0.1   [[1254, 0], [6, 0]]  0.995238\n",
       "9       1000    0.5   [[1253, 1], [6, 0]]  0.994444\n",
       "10      1000    1.0   [[1252, 2], [6, 0]]  0.993651\n",
       "11      1000    5.0   [[1245, 9], [6, 0]]  0.988095\n",
       "12      1000   10.0  [[1243, 11], [6, 0]]  0.986508\n",
       "13      1000   20.0  [[1243, 11], [6, 0]]  0.986508\n",
       "14      1000   50.0  [[1243, 11], [6, 0]]  0.986508\n",
       "15      1000  100.0  [[1243, 11], [6, 0]]  0.986508\n",
       "16      3000    0.1   [[1254, 0], [6, 0]]  0.995238\n",
       "17      3000    0.5   [[1253, 1], [6, 0]]  0.994444\n",
       "18      3000    1.0   [[1253, 1], [6, 0]]  0.994444\n",
       "19      3000    5.0   [[1248, 6], [6, 0]]  0.990476\n",
       "20      3000   10.0   [[1248, 6], [6, 0]]  0.990476\n",
       "21      3000   20.0   [[1248, 6], [6, 0]]  0.990476\n",
       "22      3000   50.0   [[1248, 6], [6, 0]]  0.990476\n",
       "23      3000  100.0   [[1248, 6], [6, 0]]  0.990476"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_df = pd.DataFrame(SVM_list)\n",
    "SVM_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147a7319",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experiment ENdss-------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7fb852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "35e83389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9952380952380953"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dummy Classification\n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X_train, Y_train)\n",
    "DummyClassifier(strategy='most_frequent')\n",
    "dummy_pred = dummy_clf.predict(X_test)\n",
    "# array([1, 1, 1, 1])\n",
    "dummy_clf.score(X_test, y_test)\n",
    "# print(f'Dummy Classifier -------------------\\n{classification_report(y_test, dummy_pred)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a0bb4cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Reports\n",
      "\n",
      "Dummy Classifer -------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   NonSevere       1.00      1.00      1.00      1254\n",
      "      Severe       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           1.00      1260\n",
      "   macro avg       0.50      0.50      0.50      1260\n",
      "weighted avg       0.99      1.00      0.99      1260\n",
      "\n",
      "\n",
      "MultinomialNB -------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   NonSevere       1.00      1.00      1.00      1254\n",
      "      Severe       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.99      1260\n",
      "   macro avg       0.50      0.50      0.50      1260\n",
      "weighted avg       0.99      0.99      0.99      1260\n",
      "\n",
      "\n",
      "Logistic Regression-------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   NonSevere       1.00      1.00      1.00      1254\n",
      "      Severe       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           1.00      1260\n",
      "   macro avg       0.50      0.50      0.50      1260\n",
      "weighted avg       0.99      1.00      0.99      1260\n",
      "\n",
      "\n",
      "SVM -------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   NonSevere       1.00      1.00      1.00      1254\n",
      "      Severe       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.99      1260\n",
      "   macro avg       0.50      0.50      0.50      1260\n",
      "weighted avg       0.99      0.99      0.99      1260\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Classification Reports\\n')\n",
    "print(f'Dummy Classifer -------------------\\n{classification_report(y_test, dummy_pred)}\\n')\n",
    "print(f'MultinomialNB -------------------\\n{classification_report(y_test, MultinomialNB_pred)}\\n')\n",
    "print(f'Logistic Regression-------------------\\n{classification_report(y_test, lr_pred)}\\n')\n",
    "print(f'SVM -------------------\\n{classification_report(y_test, svm_pred)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ab0941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------FInalise code until here--- delete the below cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9154fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenised the training data again and stored into a different variable\n",
    "trainingdata_tokenised = []\n",
    "for i in range(0,trainingdataset):\n",
    "    review = nlpsteps(str(training_data_df['Summary'][i]))\n",
    "    trainingdata_tokenised.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564a29e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingdata_tokenised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0daaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count Vectorised the Summary text in the training data and this for and transforms the \"tokenised Summary\" into an array\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features = 1000)\n",
    "X_train = cv.fit_transform(trainingdata_tokenised).toarray()\n",
    "Y_train = training_data.iloc[:, -2].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dd3431",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71aef6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fceb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee555526",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenised the testing data\n",
    "testingdata_tokenised = []\n",
    "for i in range(0,testingdataset):\n",
    "    review = nlpsteps(str(testing_data_df['Summary'][i]))\n",
    "    testingdata_tokenised.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d32b9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "testingdata_tokenised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c16d6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectorixer and only transform the testing data, this will return the tokenised summary of testing data into an array\n",
    "testingdata_vector = cv.transform(testingdata_tokenised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2861b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFid Vs COuntVerctorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3941b770",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testingdata_vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381fcf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = testingdata_vector.toarray()\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea811b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = testing_data_df.iloc[:, -2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e20d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bc5680",
   "metadata": {},
   "source": [
    "# Training the Naive Bayes Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f6ad7d",
   "metadata": {},
   "source": [
    "## MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edac3936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477927d7",
   "metadata": {},
   "source": [
    "### Predicting the TestSet Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2724f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "MultinomialNB_pred = classifier.predict(X_test)\n",
    "print(np.concatenate((MultinomialNB_pred.reshape(len(MultinomialNB_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f24d0d",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e15e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "cm = confusion_matrix(y_test, MultinomialNB_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, MultinomialNB_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab721c0d",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e01adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d16e67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred = lr_model.predict(X_test)\n",
    "print(np.concatenate((lr_pred.reshape(len(lr_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edbb10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score,classification_report\n",
    "cm_lr = confusion_matrix(y_test, lr_pred)\n",
    "print(cm_lr)\n",
    "accuracy_score(y_test, lr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80d60cd",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7b895b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experiment starts here-------------------------------------\n",
    "C_hyperparameter = [0.1,0.5, 1, 5, 10, 20, 50, 100]\n",
    "C_hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc84ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score,classification_report\n",
    "\n",
    "\n",
    "SVM_list= []\n",
    "SVM_accuracy_list = []\n",
    "for i in C_hyperparameter:\n",
    "    SVM_dict = {}\n",
    "    \n",
    "    svm_model = SVC(C = i, kernel='linear', gamma='auto')\n",
    "    svm_model.fit(X_train,Y_train)\n",
    "    \n",
    "    svm_pred = svm_model.predict(X_test)\n",
    "    svm_model = confusion_matrix(y_test, svm_pred)\n",
    "    \n",
    "    SVM_accuracy_list= accuracy_score(y_test, svm_pred)\n",
    "    SVM_dict = {\"C\":i, \"confusionmatrix\":svm_model,\"Accuracy\": SVM_accuracy_list }\n",
    "    SVM_list.append(SVM_dict)\n",
    "   \n",
    "    \n",
    "#     print(i,svm_model,SVM_accuracy_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5b530a",
   "metadata": {},
   "outputs": [],
   "source": [
    " SVM_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad73e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_df = pd.DataFrame(SVM_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d91c3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_df[SVM_df['Accuracy']==SVM_df['Accuracy'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1990771f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy on testing data\n",
    "\n",
    "score = accuracy_score(y_test,MultinomialNB_pred)\n",
    "print(\"MultinomialNBScore :\",round(score*100,2))\n",
    "\n",
    "score = accuracy_score(y_test,lr_pred)\n",
    "print(\"LogisticRegressiontScore :\",round(score*100,2))\n",
    "\n",
    "score = accuracy_score(y_test,svm_pred)\n",
    "print(\"SVMScore :\",round(score*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacd38bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification Reports\\n')\n",
    "print(f'Dummy Classifer -------------------\\n{classification_report(y_test, dummy_pred)}\\n')\n",
    "print(f'MultinomialNB -------------------\\n{classification_report(y_test, MultinomialNB_pred)}\\n')\n",
    "print(f'Logistic Regression-------------------\\n{classification_report(y_test, lr_pred)}\\n')\n",
    "print(f'SVM -------------------\\n{classification_report(y_test, svm_pred)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758876c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experiment ends here--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c0009d",
   "metadata": {},
   "source": [
    "# Plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607454b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used the same split train and test data done for the dictionary\n",
    "#  Tokenised training data Summary column (Call NLPStep function)\n",
    "# Get Y_train\n",
    "# Instantiate the CountVectorizer method\n",
    "# Fit and transform the training data and then return the matrix\n",
    "# Transform testing data and return the matrix. \n",
    "# Fit in the ML Model\n",
    "# Pred on testing data\n",
    "# Get the confusion matrix\n",
    "# Get the classifciatioin report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b395363f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nov 24,2022 meeting\n",
    "#Remove Naive bayes Models: done\n",
    "# Big data set: done 51 thsnd dataset now\n",
    "#SVM: get the best C parameter with validation dataset : done 0.1,0.5, 1, 5, 10, 20, 50 100\n",
    "#Confirm S3 and Normal in Bugzilla:  done they are non severe\n",
    "#Count Vectorizer: fit-transform 10000 features, try max: done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f94639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive bayes Models will be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7b4fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort by R1 and R2 \n",
    "#threshold for Severe and Non Severe\n",
    "# SKLearn Classifier >fazizdictionaryClassifer > \n",
    "#how ro operate dictioanry on unlabled data\n",
    "\n",
    "# sorted(payload_train)\n",
    "\n",
    "July 14,2022\n",
    "#min value for R1 R2\n",
    "#Save the sorted dictionary in a new dictionaries\n",
    "#Severe | Non Severe | Mix | none\n",
    "#Create your own classification function take a sentence  and check in both dictionaries\n",
    "\n",
    "#Test the dictionary with test data\n",
    "#check if the word from test is available in the dictionary\n",
    "#Find which ratio is higher severe or non severe\n",
    "#tag that word as severe or non-severe based on the higher ratio\n",
    "\n",
    "#Remove the Enhancemments records from the bug list\n",
    "#separate Severe and NonSevere based on the greater occurence\n",
    "# Evaluate train test\n",
    "\n",
    "# function that returns the number of each unique words in the corpus\n",
    "# function to find the frequency of the word in each category Severe | Non Severe\n",
    "#feature selection\n",
    "\n",
    "# dictionary = {\n",
    "    \n",
    "#     Severe:[\"production\",\"blocked\",\"crashed\",\"shutdown\"]\n",
    "#     NonSevere:[\"scroll\",\"menu\",\"miss\"]\n",
    "# }\n",
    "\n",
    "## Find word frequency here from the corpus\n",
    "# TF-IDF Vectorizer\n",
    "#Frequency--- of words in 1 category Severe| NonSevere\n",
    "#feature selction\n",
    "#words appear in 1 category most than another\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b9d58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hypernyms\n",
    "#Synonyms\n",
    "#wordnet\n",
    "#word embedding\n",
    "#Search existing dic for bug severity\n",
    "#sentimental finance-- read\n",
    "#0.1 to 1000 for SVM C para\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0858fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLP Steps to be in 1 function so that we can call it for validation and test data set: Done\n",
    "#find all combinaton of both above threshold list: \n",
    "#Severe = severe TP\n",
    "#Severe =Nonsevere FP\n",
    "#NonSevere= NonSevere = TN\n",
    "#NonSevere = Severe = FN\n",
    "#res_r2 should be inside the function Not yet\n",
    "\n",
    "#------------------------------****----------------------------------------\n",
    "# F1Score done\n",
    "# FInd the best threshold which has a highest F1score done\n",
    "# Test the testing dataset with the best threshold done\n",
    "# ML models revamp No Yet\n",
    "# Clean Notebook InProgress\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3cd955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision = TP/TP+FP\n",
    "# Recall = TP/TP+FN\n",
    "#F1-Score = 2 * Precision *Recall/Precision + Recall\n",
    "# for i in possibleThesholdCombination[0:1]:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
