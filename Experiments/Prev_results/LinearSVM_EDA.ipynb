{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7440a3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "categories = ['Severe', 'Non-severe']\n",
    "eclipse_bugs = [30, 70]  # Example data for Eclipse\n",
    "firefox_bugs = [45, 55]  # Example data for Firefox\n",
    "\n",
    "x = np.arange(len(categories))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bars1 = ax.bar(x - width/2, eclipse_bugs, width, label='Eclipse')\n",
    "bars2 = ax.bar(x + width/2, firefox_bugs, width, label='Firefox')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_xlabel('Bug Type')\n",
    "ax.set_ylabel('Number of Bugs')\n",
    "ax.set_title('Data Distribution in Eclipse and Firefox')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(categories)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8f91422",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'helper'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5d/403ycky539l56zh62k4t0x9m0000gn/T/ipykernel_15736/8724709.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'helper'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5697ece",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bugs_df= pd.read_csv(\"bugs_Calendar.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# Dropped rows with severity level '--'\n",
    "bugs_df = bugs_df[bugs_df[\"Severity\"].str.contains(\"--\")==False].reset_index()\n",
    "\n",
    "#Dropped rows with Type \"Enhancement\" and \"Task\" because they are not a bug but a new feature\n",
    "indexSevere = bugs_df[ (bugs_df['Type'] == 'enhancement') & (bugs_df['Type'] == 'enhancement') ].index\n",
    "bugs_df.drop(indexSevere , inplace=True)\n",
    "\n",
    "indexSevere = bugs_df[(bugs_df['Type'] == 'task') & (bugs_df['Type'] == 'task') ].index\n",
    "bugs_df.drop(indexSevere , inplace=True)\n",
    "\n",
    "\n",
    "#Catagorise the severity level into a Severe and Non Severe to make it a binary problem\n",
    "bugs_df.loc[bugs_df[\"Severity\"] == \"blocker\", \"Severity\"] = 'Severe'\n",
    "bugs_df.loc[bugs_df[\"Severity\"] == \"critical\", \"Severity\"] = 'Severe'\n",
    "bugs_df.loc[bugs_df[\"Severity\"] == \"major\", \"Severity\"] = 'Severe'\n",
    "bugs_df.loc[bugs_df[\"Severity\"] == \"S1\", \"Severity\"] = 'Severe'\n",
    "bugs_df.loc[bugs_df[\"Severity\"] == \"S2\", \"Severity\"] = 'Severe'\n",
    "bugs_df.loc[bugs_df[\"Severity\"] == \"S3\", \"Severity\"] = 'NonSevere'\n",
    "bugs_df.loc[bugs_df[\"Severity\"] == \"normal\", \"Severity\"] = 'NonSevere'\n",
    "bugs_df.loc[bugs_df[\"Severity\"] == \"minor\", \"Severity\"] = 'NonSevere'\n",
    "bugs_df.loc[bugs_df[\"Severity\"] == \"trivial\", \"Severity\"] = 'NonSevere'\n",
    "bugs_df.loc[bugs_df[\"Severity\"] == \"S4\", \"Severity\"] = 'NonSevere'\n",
    "\n",
    "bugs_df = bugs_df.head(20)\n",
    "print(bugs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d49141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the preprocessing function to the 'Summary' column\n",
    "bugs_df['Processed_Summary'] = bugs_df['Summary'].apply(lambda x: helper.nlpsteps(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f5b68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bugs_df['Lowered_Summary'] = bugs_df['Processed_Summary'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f736b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bugs_df['Lowered_Summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ed541ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bugs_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5d/403ycky539l56zh62k4t0x9m0000gn/T/ipykernel_15736/1657390753.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Initialize CountVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbugs_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Lowered_Summary'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Transform the processed summaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bugs_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming you've already imported necessary libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "cv.fit(bugs_df['Lowered_Summary'])\n",
    "\n",
    "# Transform the processed summaries\n",
    "X_train = cv.transform(bugs_df['Lowered_Summary'])\n",
    "\n",
    "\n",
    "# Assuming 'target' is correctly defined\n",
    "target = bugs_df.iloc[:, -2].values\n",
    "print(\"target\", target)\n",
    "\n",
    "# Initialize LinearSVC\n",
    "svm = LinearSVC()\n",
    "\n",
    "# Fit the model\n",
    "svm.fit(X_train, target)\n",
    "\n",
    "# Get the coefficients from the trained SVM model\n",
    "coef = svm.coef_.ravel()\n",
    "\n",
    "# Get the feature names from CountVectorizer\n",
    "feature_names = cv.get_feature_names()\n",
    "\n",
    "# Create a dictionary mapping feature names to coefficients\n",
    "word_coefficients = {feature_names[i]: coef[i] for i in range(len(feature_names))}\n",
    "\n",
    "print(word_coefficients)\n",
    "\n",
    "# Print the word list and their coefficients\n",
    "for word, coefficient in word_coefficients.items():\n",
    "#     print(f\"{word}: {coefficient:.4f}\")\n",
    "\n",
    "    if coefficient < 0:\n",
    "        severe_lexicons[word] = {\"ratio\": coefficient}\n",
    "    else:\n",
    "        non_severe_lexicons[word] = {\"ratio\": coefficient}\n",
    "\n",
    "result = {\n",
    "    \"Severe Lexicons\": severe_lexicons,\n",
    "    \"NonSevere Lexicon\": non_severe_lexicons\n",
    "}\n",
    "\n",
    "print(result)\n",
    "\n",
    "\n",
    "# severe_lexicons = {}\n",
    "# non_severe_lexicons = {}\n",
    "\n",
    "# for word, coefficient in word_coefficients.items():\n",
    "#     if coefficient < 0:\n",
    "#         severe_lexicons[word] = {\"ratio\": coefficient}\n",
    "#     else:\n",
    "#         non_severe_lexicons[word] = {\"ratio\": coefficient}\n",
    "\n",
    "# result = {\n",
    "#     \"Severe Lexicons\": severe_lexicons,\n",
    "#     \"NonSevere Lexicon\": non_severe_lexicons\n",
    "# }\n",
    "\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0903a8a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# def plot_coefficients(classifier, feature_names, top_features=20):\n",
    "#     coef = classifier.coef_.ravel()\n",
    "#     top_positive_coefficients = np.argsort(coef)[-top_features:]\n",
    "#     top_negative_coefficients = np.argsort(coef)[:top_features]\n",
    "#     top_coefficients = np.hstack([top_negative_coefficients, top_positive_coefficients])\n",
    "\n",
    "#     # create plot\n",
    "#     plt.figure(figsize=(15, 5))\n",
    "#     colors = ['red' if c < 0 else 'blue' for c in coef[top_coefficients]]\n",
    "#     plt.bar(np.arange(2 * top_features), coef[top_coefficients], color=colors)\n",
    "#     feature_names = np.array(feature_names)\n",
    "#     plt.xticks(np.arange(1, 1 + 2 * top_features), feature_names[top_coefficients], rotation=60, ha='right')\n",
    "#     plt.show()\n",
    "\n",
    "# cv = CountVectorizer()\n",
    "# cv.fit(bugs_df['Summary'])\n",
    "# print(\"length\", len(cv.vocabulary_))\n",
    "# print(\"Feature Names\", cv.get_feature_names())\n",
    "# X_train = cv.transform(bugs_df['Summary'])\n",
    "# target = bugs_df.iloc[:, -2].values\n",
    "# print(\"target\",target)\n",
    "\n",
    "# svm = LinearSVC()\n",
    "# svm.fit(X_train, target)\n",
    "# plot_coefficients(svm, cv.get_feature_names())\n",
    "\n",
    "# #Get the coefficients from the trained SVM model\n",
    "# coef = svm.coef_.ravel()\n",
    "\n",
    "# # Get the feature names from the CountVectorizer\n",
    "# feature_names = cv.get_feature_names()\n",
    "\n",
    "# # Create a dictionary mapping feature names to coefficients\n",
    "# word_coefficients = {feature_names[i]: coef[i] for i in range(len(feature_names))}\n",
    "\n",
    "# # Print the word list and their coefficients\n",
    "# for word, coefficient in word_coefficients.items():\n",
    "#     print(f\"{word}: {coefficient:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6f6b32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73f945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # [ 1  2  8  9 11 12 16 17 18 19]\n",
    "# def plot_coefficients(classifier, feature_names, top_features=30):\n",
    "#     coef = classifier.coef_.ravel()\n",
    "#     top_positive_coefficients = np.argsort(coef)[-top_features:]\n",
    "#     top_negative_coefficients = np.argsort(coef)[:top_features]\n",
    "#     top_coefficients = np.hstack([top_negative_coefficients, top_positive_coefficients])\n",
    "\n",
    "#     # create plot\n",
    "#     plt.figure(figsize=(15, 5))\n",
    "#     colors = ['red' if c < 0 else 'blue' for c in coef[top_coefficients]]\n",
    "#     plt.bar(np.arange(2 * top_features), coef[top_coefficients], color=colors)\n",
    "#     feature_names = np.array(feature_names)\n",
    "#     plt.xticks(np.arange(1, 1 + 2 * top_features), feature_names[top_coefficients], rotation=60, ha='right')\n",
    "#     plt.show()\n",
    "\n",
    "# cv = CountVectorizer()\n",
    "# cv.fit(bugs_df['Summary'])\n",
    "# X_train = cv.transform(bugs_df['Summary'])\n",
    "# # print(bugs_df['Summary'])\n",
    "# target = bugs_df.iloc[:, -2].values\n",
    "# # print(target)\n",
    "\n",
    "# # Separate the data into severe and non-severe classes\n",
    "# severe_indices = np.where(target == 'Severe')[0]\n",
    "# non_severe_indices = np.where(target == 'NonSevere')[0]\n",
    "\n",
    "# print(\"severe_indices\", severe_indices)\n",
    "# print(\"non_severe_indices\", non_severe_indices)\n",
    "\n",
    "# # Train separate SVM models for severe and non-severe classes\n",
    "# svm_severe = LinearSVC()\n",
    "# svm_severe.fit(X_train[severe_indices], target[severe_indices])\n",
    "# print(svm_severe)\n",
    "\n",
    "# svm_non_severe = LinearSVC()\n",
    "# svm_non_severe.fit(X_train[non_severe_indices], target[non_severe_indices])\n",
    "\n",
    "# # Get the coefficients from the trained SVM models\n",
    "# coef_severe = svm_severe.coef_.ravel()\n",
    "# coef_non_severe = svm_non_severe.coef_.ravel()\n",
    "\n",
    "# # Create dictionaries mapping feature names to coefficients for severe and non-severe classes\n",
    "# word_coefficients_severe = {feature_names[i]: coef_severe[i] for i in range(len(feature_names))}\n",
    "# word_coefficients_non_severe = {feature_names[i]: coef_non_severe[i] for i in range(len(feature_names))}\n",
    "\n",
    "# # Print the word list and their coefficients for both classes\n",
    "# for word in feature_names:\n",
    "#     print(f\"{word}: Severe={word_coefficients_severe.get(word, 0):.4f}, Non-Severe={word_coefficients_non_severe.get(word, 0):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82257c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe097ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43140c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
