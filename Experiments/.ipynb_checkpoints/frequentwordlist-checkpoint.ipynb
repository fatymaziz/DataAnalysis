{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8462b4d8-16b0-4906-a884-419170a28d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/fatimaa/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "671359ad-c4b1-4840-ac3d-3bf9ae2241f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bugs_eclipse = pd.read_csv(\"bugs_eclipse.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2dd67f7-a754-447e-8c51-b89ce730e9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       index  Bug ID             Product           Component  \\\n",
      "31028  31028  148084  WTP Source Editing             wst.xsd   \n",
      "31029  31029  240170  WTP Source Editing           wst.xpath   \n",
      "31030  31030  129714  WTP Source Editing             jst.jsp   \n",
      "31031  31031  103180     WTP Webservices              jst.ws   \n",
      "31032  31032   86408  WTP Source Editing             wst.xml   \n",
      "31033  31033  130236  WTP Source Editing             wst.xml   \n",
      "31034  31034  112397  WTP Source Editing             jst.jsp   \n",
      "31035  31035  105732   WTP Java EE Tools            jst.j2ee   \n",
      "31036  31036  296188   Java Server Faces                Core   \n",
      "31037  31037  242877     WTP Webservices            wst.wsdl   \n",
      "31038  31038  250882          WTP Releng              releng   \n",
      "31039  31039  273201  WTP Source Editing             wst.xml   \n",
      "31040  31040  411994   Java Server Faces                  UI   \n",
      "31041  31041  180741   WTP Java EE Tools            jst.j2ee   \n",
      "31042  31042  101782   WTP Java EE Tools            jst.j2ee   \n",
      "31043  31043  171730   Java Server Faces                  UI   \n",
      "31044  31044   89199  WTP Source Editing             jst.jsp   \n",
      "31045  31045  209288     WTP Webservices            wst.wsdl   \n",
      "31046  31046   75942           Web Tools  Web Standard Tools   \n",
      "31047  31047  322559     WTP ServerTools          wst.server   \n",
      "31048  31048  289564     WTP ServerTools          wst.server   \n",
      "31049  31049   87532   WTP Java EE Tools         jst.servlet   \n",
      "31050  31050  161656  WTP Source Editing             wst.sse   \n",
      "31051  31051  267799     WTP ServerTools          wst.server   \n",
      "31052  31052  144806   Java Server Faces                Core   \n",
      "31053  31053  111805  WTP Source Editing             jst.jsp   \n",
      "31054  31054  144868  WTP Source Editing             jst.jsp   \n",
      "31055  31055  138008  WTP Source Editing             wst.dtd   \n",
      "31056  31056  124110  WTP Source Editing             jst.jsp   \n",
      "31057  31057  110266  WTP Source Editing             wst.sse   \n",
      "31058  31058   81651  WTP Source Editing             wst.xsd   \n",
      "31059  31059  289906     WTP ServerTools          wst.server   \n",
      "31060  31060  103769  WTP Source Editing            wst.html   \n",
      "31061  31061  234391       WTP EJB Tools             jst.ejb   \n",
      "31129  31129  131526   WTP Java EE Tools         jst.servlet   \n",
      "31130  31130   86031   WTP Java EE Tools            jst.j2ee   \n",
      "31131  31131  290337  WTP Source Editing           wst.xpath   \n",
      "31132  31132  266341   WTP Java EE Tools            jst.j2ee   \n",
      "31133  31133  249314          WTP Releng              releng   \n",
      "31134  31134  260218   WTP Java EE Tools            jst.j2ee   \n",
      "31135  31135  105106   WTP Java EE Tools            jst.j2ee   \n",
      "31136  31136  138339  WTP Source Editing             wst.xsd   \n",
      "31137  31137   86351     WTP Webservices            wst.wsdl   \n",
      "31138  31138  126503  WTP Source Editing             wst.xml   \n",
      "31139  31139   81652  WTP Source Editing             wst.xsd   \n",
      "31140  31140  157542  WTP Source Editing             wst.xsd   \n",
      "31141  31141  285253  WTP Source Editing             wst.xsd   \n",
      "31142  31142   80558  WTP Source Editing             wst.sse   \n",
      "31143  31143  178513   Java Server Faces                  UI   \n",
      "31144  31144  246427  WTP Source Editing             wst.xml   \n",
      "\n",
      "                                Assignee    Status   Resolution  \\\n",
      "31028           keith.chong.ca@gmail.com    CLOSED   WORKSFORME   \n",
      "31029               d_a_carver@yahoo.com  RESOLVED        FIXED   \n",
      "31030            sarika.sinha@in.ibm.com  RESOLVED        FIXED   \n",
      "31031                  pmoogk@ca.ibm.com    CLOSED   WORKSFORME   \n",
      "31032             david_williams@acm.org  RESOLVED   WORKSFORME   \n",
      "31033               thatnitind@gmail.com  RESOLVED   WORKSFORME   \n",
      "31034             david_williams@acm.org  RESOLVED   WORKSFORME   \n",
      "31035                 mdelder@us.ibm.com    CLOSED      WONTFIX   \n",
      "31036         jsf.core-inbox@eclipse.org       NEW          ---   \n",
      "31037       wst.wsdl-triaged@eclipse.org       NEW          ---   \n",
      "31038  webtools.releng-inbox@eclipse.org       NEW          ---   \n",
      "31039          valentinbaciu@hotmail.com    CLOSED  NOT_ECLIPSE   \n",
      "31040         cameron.bateman@oracle.com       NEW          ---   \n",
      "31041                     ccc@us.ibm.com       NEW          ---   \n",
      "31042                 zalapa@mx1.ibm.com       NEW          ---   \n",
      "31043        debajit.adhikary@oracle.com       NEW          ---   \n",
      "31044             david_williams@acm.org  RESOLVED        FIXED   \n",
      "31045       wst.wsdl-triaged@eclipse.org       NEW          ---   \n",
      "31046              wst-inbox@eclipse.org    CLOSED      INVALID   \n",
      "31047                  arvera@ca.ibm.com    CLOSED   WORKSFORME   \n",
      "31048                  arvera@ca.ibm.com       NEW          ---   \n",
      "31049                  jsholl@us.ibm.com    CLOSED      WONTFIX   \n",
      "31050                nsand.dev@gmail.com  RESOLVED        FIXED   \n",
      "31051                  arvera@ca.ibm.com       NEW          ---   \n",
      "31052         cameron.bateman@oracle.com  VERIFIED        FIXED   \n",
      "31053                nsand.dev@gmail.com  RESOLVED        FIXED   \n",
      "31054                nsand.dev@gmail.com  RESOLVED   WORKSFORME   \n",
      "31055          for.work.things@gmail.com    CLOSED        FIXED   \n",
      "31056                 zalapa@mx1.ibm.com       NEW          ---   \n",
      "31057        wst.sse-triaged@eclipse.org  RESOLVED      WONTFIX   \n",
      "31058           keith.chong.ca@gmail.com    CLOSED        FIXED   \n",
      "31059                  arvera@ca.ibm.com       NEW          ---   \n",
      "31060            sarika.sinha@in.ibm.com    CLOSED    DUPLICATE   \n",
      "31061               petya.sabeva@sap.com    CLOSED        FIXED   \n",
      "31129                 jlanuti@us.ibm.com    CLOSED    DUPLICATE   \n",
      "31130                 jlanuti@us.ibm.com    CLOSED      WONTFIX   \n",
      "31131               jesper@selskabet.org  RESOLVED        FIXED   \n",
      "31132                     ccc@us.ibm.com  RESOLVED   WORKSFORME   \n",
      "31133             david_williams@acm.org  RESOLVED      WONTFIX   \n",
      "31134               shr31223@hotmail.com  RESOLVED      WONTFIX   \n",
      "31135                cbridgha@us.ibm.com    CLOSED   WORKSFORME   \n",
      "31136           keith.chong.ca@gmail.com    CLOSED      WONTFIX   \n",
      "31137          for.work.things@gmail.com    CLOSED      WONTFIX   \n",
      "31138             david_williams@acm.org  RESOLVED      WONTFIX   \n",
      "31139           keith.chong.ca@gmail.com    CLOSED   WORKSFORME   \n",
      "31140        wst.xsd-triaged@eclipse.org       NEW          ---   \n",
      "31141                  atosak@ca.ibm.com  ASSIGNED          ---   \n",
      "31142          wst.sse-inbox@eclipse.org    CLOSED      WONTFIX   \n",
      "31143             ian.trimble@oracle.com    CLOSED   WORKSFORME   \n",
      "31144                rakes123@in.ibm.com  RESOLVED        FIXED   \n",
      "\n",
      "                                                 Summary           Changed  \\\n",
      "31028          Context menu contents while editing names  21/01/2008 16:42   \n",
      "31029  [xslt][editor] XPath content assist does not n...  11/08/2010 17:08   \n",
      "31030    [formatting] Cleanup does not affect directives  07/12/2010 16:02   \n",
      "31031  Excessive WTP plugins activated on startup in ...  12/09/2005 13:51   \n",
      "31032  source validation disappears for element betwe...  30/04/2010 14:32   \n",
      "31033  [content model] Unable to load dtd if no encod...  20/12/2012 16:17   \n",
      "31034                    [perf] JSP Indexing performance   16/02/2010 8:31   \n",
      "31035  [project explorer] j2ee content provider does ...  16/06/2006 13:20   \n",
      "31036  [WPE] StackOverflowError when page with circul...  31/03/2016 17:14   \n",
      "31037         [editor] Inconsistent empty element format  20/07/2010 11:36   \n",
      "31038                  source files incorrectly encoded?  21/09/2011 12:37   \n",
      "31039                       'name' is not 'name' anymore  02/11/2009 15:33   \n",
      "31040  Javascript validation - JSTL var in function name  31/03/2016 17:18   \n",
      "31041            Add Remove still shows old project name  12/06/2008 11:02   \n",
      "31042  [validation] validation.sample project should ...  19/01/2011 14:26   \n",
      "31043  [faces-config editor] Saves source file three ...  31/03/2016 17:11   \n",
      "31044        jsp-syntax coloring fails on nested if-else  15/02/2010 18:09   \n",
      "31045                 [editor] NPE when doubleclick port   15/05/2013 6:17   \n",
      "31046         [Login] datagrid for returned search items  28/11/2006 15:40   \n",
      "31047                Widget is disposed on Run On Server  17/02/2011 14:14   \n",
      "31048  Servers not deleted after deleting renamed run...  13/01/2010 13:36   \n",
      "31049            Can't remove libraries from WEB-INF/lib  26/06/2006 16:49   \n",
      "31050  [ui] Task Tags preference page Filters tab sho...  15/11/2010 15:25   \n",
      "31051              Why exclude servers with no runtimes?  17/12/2009 15:55   \n",
      "31052  TaglibContextResolver does not validate attrib...  20/09/2007 19:01   \n",
      "31053     JSP Java content assist shows private members?  11/05/2009 20:50   \n",
      "31054  JSP parser : <%=\"\"-\"\"%> is validated as a corr...  08/12/2009 13:25   \n",
      "31055  dtd property sheet elements are not laid out n...  19/06/2006 17:47   \n",
      "31056  [ui] wrong positioning of parenthesis in jsp code  24/07/2013 12:55   \n",
      "31057  [editor] ClassCastExceptions when perform some...  22/11/2013 15:41   \n",
      "31058  XSDEditor properties view is blank when clicki...  20/12/2007 12:31   \n",
      "31059         Server Audio settings don't appear to play  14/01/2010 10:49   \n",
      "31060  [content assist] Content assist not shown in a...  13/05/2010 13:52   \n",
      "31061              Missing icon for the EJB Module facet  06/11/2008 14:23   \n",
      "31129                 NPE in WebServletGroupItemProvider  26/09/2006 10:16   \n",
      "31130                      Servlet Wiz: Add toolbar icon  25/01/2006 11:03   \n",
      "31131  [patch][xpath2] revisit use of ICU's Normalize...  11/08/2010 17:08   \n",
      "31132      Can not create EJB project  for JBoss runtime   29/05/2009 4:38   \n",
      "31133  XSL Tools 1.0M series not showing as a separat...  17/01/2010 15:41   \n",
      "31134  Publishing to Tomcat: ZipException: duplicate ...  01/05/2012 15:30   \n",
      "31135  [project explorer] J2EE Perspective CVS decora...  15/02/2010 14:25   \n",
      "31136                   Give buttons with dots a meaning  03/04/2007 11:48   \n",
      "31137  XSDEditor: Context menu actions (which edit) a...  07/11/2008 15:44   \n",
      "31138  Some JUnit encoding charset tests sensitive to...  30/04/2010 14:28   \n",
      "31139  XSDEditor: Back To Schema context menu item ap...  26/09/2006 13:56   \n",
      "31140  [editor] probable translation faux pas in AddE...  16/09/2010 14:35   \n",
      "31141  [properties] NPE thrown from plug-in org.eclip...  27/10/2011 15:09   \n",
      "31142  HighlighterHyperlinkPresenter does not underli...  30/06/2005 14:29   \n",
      "31143        labels w/ yellow foregroudn hardly readable  08/05/2008 19:53   \n",
      "31144  [content model] New XML Wizard generates EMPTY...  23/08/2010 17:17   \n",
      "\n",
      "      Priority   Severity    Type  \n",
      "31028       P4  NonSevere  defect  \n",
      "31029       P4  NonSevere  defect  \n",
      "31030       P4  NonSevere  defect  \n",
      "31031       P4  NonSevere  defect  \n",
      "31032       P4  NonSevere  defect  \n",
      "31033       P4  NonSevere  defect  \n",
      "31034       P4  NonSevere  defect  \n",
      "31035       P4  NonSevere  defect  \n",
      "31036       P4  NonSevere  defect  \n",
      "31037       P4  NonSevere  defect  \n",
      "31038       P4  NonSevere  defect  \n",
      "31039       P4  NonSevere  defect  \n",
      "31040       P4  NonSevere  defect  \n",
      "31041       P4  NonSevere  defect  \n",
      "31042       P4  NonSevere  defect  \n",
      "31043       P4  NonSevere  defect  \n",
      "31044       P4  NonSevere  defect  \n",
      "31045       P4  NonSevere  defect  \n",
      "31046       P4  NonSevere  defect  \n",
      "31047       P4  NonSevere  defect  \n",
      "31048       P4  NonSevere  defect  \n",
      "31049       P4  NonSevere  defect  \n",
      "31050       P4  NonSevere  defect  \n",
      "31051       P4  NonSevere  defect  \n",
      "31052       P4  NonSevere  defect  \n",
      "31053       P4  NonSevere  defect  \n",
      "31054       P4  NonSevere  defect  \n",
      "31055       P4  NonSevere  defect  \n",
      "31056       P4  NonSevere  defect  \n",
      "31057       P4  NonSevere  defect  \n",
      "31058       P4  NonSevere  defect  \n",
      "31059       P4  NonSevere  defect  \n",
      "31060       P4  NonSevere  defect  \n",
      "31061       P4  NonSevere  defect  \n",
      "31129       P5     Severe  defect  \n",
      "31130       P5  NonSevere  defect  \n",
      "31131       P5  NonSevere  defect  \n",
      "31132       P5  NonSevere  defect  \n",
      "31133       P5  NonSevere  defect  \n",
      "31134       P5  NonSevere  defect  \n",
      "31135       P5  NonSevere  defect  \n",
      "31136       P5  NonSevere  defect  \n",
      "31137       P5  NonSevere  defect  \n",
      "31138       P5  NonSevere  defect  \n",
      "31139       P5  NonSevere  defect  \n",
      "31140       P5  NonSevere  defect  \n",
      "31141       P5  NonSevere  defect  \n",
      "31142       P5  NonSevere  defect  \n",
      "31143       P5  NonSevere  defect  \n",
      "31144       P5  NonSevere  defect  \n",
      "total bugs 50\n",
      "Severity\n",
      "NonSevere    49\n",
      "Severe        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "bugs_eclipse['Type'] = np.where(bugs_eclipse['Severity'] == 'enhancement', \"enhancement\", \"defect\")\n",
    "bugs_df = pd.concat([bugs_eclipse])\n",
    "\n",
    "# Dropped rows with severity level '--'\n",
    "bugs_df = bugs_df[bugs_df[\"Severity\"].str.contains(\"--\")==False].reset_index()\n",
    "\n",
    "#Dropped rows with Type \"Enhancement\" and \"Task\" because they are not a bug but a new feature\n",
    "indexSevere = bugs_df[ (bugs_df['Type'] == 'enhancement') & (bugs_df['Type'] == 'enhancement') ].index\n",
    "bugs_df.drop(indexSevere , inplace=True)\n",
    "\n",
    "indexSevere = bugs_df[ (bugs_df['Type'] == 'task') & (bugs_df['Type'] == 'task') ].index\n",
    "bugs_df.drop(indexSevere , inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "#Catagorise the severity level into a Severe and Non Severe to make it a binary problem\n",
    "bugs_df.loc[bugs_df[\"Severity\"] == \"blocker\", \"Severity\"] = 'Severe'\n",
    "bugs_df.loc[bugs_df[\"Severity\"] == \"critical\", \"Severity\"] = 'Severe'\n",
    "bugs_df.loc[bugs_df[\"Severity\"] == \"major\", \"Severity\"] = 'Severe'\n",
    "bugs_df.loc[bugs_df[\"Severity\"] == \"S1\", \"Severity\"] = 'Severe'\n",
    "bugs_df.loc[bugs_df[\"Severity\"] == \"S2\", \"Severity\"] = 'Severe'\n",
    "bugs_df.loc[bugs_df[\"Severity\"] == \"S3\", \"Severity\"] = 'NonSevere'\n",
    "bugs_df.loc[bugs_df[\"Severity\"] == \"normal\", \"Severity\"] = 'NonSevere'\n",
    "bugs_df.loc[bugs_df[\"Severity\"] == \"minor\", \"Severity\"] = 'NonSevere'\n",
    "bugs_df.loc[bugs_df[\"Severity\"] == \"trivial\", \"Severity\"] = 'NonSevere'\n",
    "bugs_df.loc[bugs_df[\"Severity\"] == \"S4\", \"Severity\"] = 'NonSevere'\n",
    "\n",
    "bugs_df = bugs_df.tail(50)\n",
    "print(bugs_df)\n",
    "print(\"total bugs\", len(bugs_df))\n",
    "severerity = bugs_df['Severity'].value_counts()\n",
    "print(severerity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a1d193-fb0a-42e8-9742-248ed0c1eb5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "482df686-fc67-4080-97c9-5115011dce1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bugs_eclipse_length = len(bugs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "448171e1-11b5-4359-bcd6-b8c104e438d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bugs_eclipse_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10058ef0-4031-44de-ad7f-82c933ba6cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlpsteps(x):\n",
    "    \"\"\"\n",
    "    Tokenizes and preprocesses a summary of a bug.\n",
    "\n",
    "    Args:\n",
    "        x (str): The summary text to be processed.\n",
    "\n",
    "    Returns:\n",
    "        str: The processed text after removing non-alphabetic characters, converting to lowercase,\n",
    "             lemmatizing words, and removing stopwords.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Remove non-alphabetic characters\n",
    "    review = re.sub('[^a-zA-Z]', ' ', str(x))\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "\n",
    "    # Initialize WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # Remove stopwords and lemmatize words\n",
    "    all_stopwords = set(stopwords.words('english'))\n",
    "    all_stopwords.remove('not')\n",
    "    review = [lemmatizer.lemmatize(word) for word in review if word not in all_stopwords]\n",
    "\n",
    "    # Join the processed words back into a sentence\n",
    "    review = ' '.join(review)\n",
    "    return review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0913b39a-acc4-4240-9536-291b6adcdf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(corpus_trainingdata):\n",
    "    \"\"\"\n",
    "    Data after preprocessing splitting into separate words\n",
    "\n",
    "    Args:\n",
    "        corpus_trainingdata: Preprocessed data of the training dataset\n",
    "     \n",
    "    Returns: Splitted words\n",
    "    \"\"\"\n",
    "#     print(\"DEMO--------------------------Corpus---------------------------\")\n",
    "#     print(corpus_trainingdata)\n",
    "    return ([i for item in corpus_trainingdata for i in item.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fd77927-c8c3-4806-b2a8-0e5e5bb8a4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distribution(val,bugs_eclipse):\n",
    "    \"\"\"\n",
    "    Data after preprocessing splitting into separate words\n",
    "\n",
    "    Args:\n",
    "        val: Preprocessed data of the training dataset\n",
    "        training_data_df: training dataset dataframe\n",
    "      \n",
    "    Returns: Splitted words\n",
    "    \"\"\"\n",
    "    bugs_eclipse['Summary'] = bugs_eclipse['Summary'].apply(lambda x: nlpsteps(x))\n",
    "    records = bugs_eclipse[\n",
    "        bugs_eclipse[\"Summary\"].str.contains(val)\n",
    "    ]\n",
    "    \n",
    "    if len(records) > 0:\n",
    "        res = bugs_eclipse[\n",
    "            training_data_df[\"Summary\"].str.contains(val)\n",
    "        ][\"Severity\"].value_counts(dropna=False)\n",
    "        return dict(res)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5df4d99-2daa-4af9-b957-91e7042cc2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexicon_preprocess(trainingdataset_length,training_data_df):\n",
    "    \"\"\"\n",
    "    Create wordlists for severe and non severe from the preprocessed training dataset \n",
    "\n",
    "    Args:\n",
    "        trainingdataset_length: size of training dataset\n",
    "        training_data_df: training dataset dataframe\n",
    "      \n",
    "    Returns: a wordlist that has words from training dataset with its counts for severe and nonsevere\n",
    "    \"\"\"\n",
    "    # print(\"trainingdataset_length\",trainingdataset_length)\n",
    "    # print(\"training_data_df\",training_data_df)\n",
    "    corpus_trainingdata = []\n",
    "    all_data_df_ = []\n",
    "       \n",
    "    for i in range(0,trainingdataset_length):\n",
    "        review = nlpsteps(str(training_data_df['Summary'][i]))\n",
    "        corpus_trainingdata.append(review)\n",
    "   \n",
    "\n",
    "#     #Split words from the corpus\n",
    "#     splittedWords = convert(corpus_trainingdata)\n",
    "# #     print(\"splittedWords---------------\", splittedWords)\n",
    "    \n",
    "#     splitted_words=getwordcounts(splittedWords)\n",
    "\n",
    "#     #Converted collection.counter into dictionary\n",
    "#     splitted_words_dict = dict(splitted_words)\n",
    "\n",
    "#     keys = splitted_words_dict.keys()\n",
    "    \n",
    "#     all_data = {}\n",
    "#     for key in keys:\n",
    "#         res = get_distribution(key,training_data_df)\n",
    "#         if res:\n",
    "#             all_data[key] = res\n",
    "#             all_data\n",
    "#             all_data_df = pd.DataFrame(all_data)\n",
    "       \n",
    "#             print(\"--------------wordlists for severe and non-severe------------------------\")\n",
    "         \n",
    "#             pd.set_option('display.max_columns', None)\n",
    "#             print(all_data_df)\n",
    "        \n",
    "\n",
    "    return all_data_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02db570e-a861-4180-af5b-948a11d45093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a28e7ab3-2f03-48da-a346-a19b2ac3b6a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m payload_train \u001b[38;5;241m=\u001b[39m \u001b[43mlexicon_preprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbugs_eclipse_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbugs_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 17\u001b[0m, in \u001b[0;36mlexicon_preprocess\u001b[0;34m(trainingdataset_length, training_data_df)\u001b[0m\n\u001b[1;32m     14\u001b[0m all_data_df_ \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,trainingdataset_length):\n\u001b[0;32m---> 17\u001b[0m     review \u001b[38;5;241m=\u001b[39m nlpsteps(\u001b[38;5;28mstr\u001b[39m(\u001b[43mtraining_data_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSummary\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m))\n\u001b[1;32m     18\u001b[0m     corpus_trainingdata\u001b[38;5;241m.\u001b[39mappend(review)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#Split words from the corpus\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "payload_train = lexicon_preprocess(bugs_eclipse_length, bugs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319de6a9-1408-439d-a41c-a13e8af60ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9fe5cf-900e-49d6-9df9-01afb380fe2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
